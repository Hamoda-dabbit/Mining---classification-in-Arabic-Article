{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamoda-dabbit/Mining---classification-in-Arabic-Article/blob/main/CNN/CNN_Tokenizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKSuILzq_b-8"
      },
      "source": [
        " 1-import library\n",
        " \n",
        "  إستيراد المكتبات"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "import re\n",
        "import string\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "# fix random seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYp37W3G3c-N",
        "outputId": "0e18de5a-98a7-4de5-9a58-80fab2e20995"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY_2pUn__oh8"
      },
      "source": [
        "--------\n",
        "\n",
        "2- import Datasets\n",
        "\n",
        "استيراد ملفات البيانات\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "ITaTjKYUJGKx",
        "outputId": "3d8d4dfd-ec35-450b-9347-20428cb69062"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-cc008cd13e08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/MyDrive/mining/1.xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# dataset = pd.read_excel(\"drive/MyDrive/mining/2.xlsx\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# dataset = pd.read_excel(\"drive/MyDrive/mining/3.xlsx\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# dataset = pd.read_excel(\"drive/MyDrive/mining/4.xlsx\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[1;32m   1190\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m                 ext = inspect_excel_format(\n\u001b[0;32m-> 1192\u001b[0;31m                     \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1193\u001b[0m                 )\n\u001b[1;32m   1194\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mext\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[0;34m(content_or_path, storage_options)\u001b[0m\n\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m     with get_handle(\n\u001b[0;32m-> 1071\u001b[0;31m         \u001b[0mcontent_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m     ) as handle:\n\u001b[1;32m   1073\u001b[0m         \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             \u001b[0;31m# Binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 711\u001b[0;31m             \u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    712\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/mining/1.xlsx'"
          ]
        }
      ],
      "source": [
        "# dataset = pd.read_excel(\"drive/MyDrive/mining/1.xlsx\")\n",
        "# dataset = pd.read_excel(\"drive/MyDrive/mining/2.xlsx\")\n",
        "# dataset = pd.read_excel(\"drive/MyDrive/mining/3.xlsx\")\n",
        "dataset = pd.read_excel(\"drive/MyDrive/mining/4.xlsx\")\n",
        "\n",
        "dataset.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pi8xU2VwUAss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjXeZSy9_fB2"
      },
      "source": [
        "------\n",
        "3- shuffle  \n",
        "بعثرة البيانات"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "n70SDzKWdM5_",
        "outputId": "d9d8fe78-72b9-48a3-dcdb-2f051ce15b39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  targe\n",
              "29519  تعهد سعد الدين العثماني رئيس الحكومه الجديد بم...      3\n",
              "42321  عبر عد من الشباب الحاملين لمشاريع بمدينه طنجه ...      2\n",
              "10209  منعت السلطات الاسبانيه مدير مكتب الجزيره باسبا...      2\n",
              "30207  وصف الميلودي مخاريق امين عام الاتحاد المغربي ل...      3\n",
              "9128   عبدالاله بوسحابه اخبارنا المغربيه بعد الفضيحه ...      2\n",
              "...                                                  ...    ...\n",
              "12824  اكد حزب العداله والتنميه الاسلامي الذي يقود ال...      3\n",
              "41515  درك الحربي اكتشف عناصر جرميه في تلقي الجنود لر...      1\n",
              "36695  شذي يتابع ملاين العرب علي مواقع التواصل الاجتم...      0\n",
              "48325  اعتبرت الملكه المغربيه مساء الثلاثاء ان الجوء ...      3\n",
              "25768  اقتنت الشركه الماليه الدوليه فرع البند الدولي ...      2\n",
              "\n",
              "[52133 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3d610ed-c300-40c4-a2e7-c1e5611867ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>targe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29519</th>\n",
              "      <td>تعهد سعد الدين العثماني رئيس الحكومه الجديد بم...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42321</th>\n",
              "      <td>عبر عد من الشباب الحاملين لمشاريع بمدينه طنجه ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10209</th>\n",
              "      <td>منعت السلطات الاسبانيه مدير مكتب الجزيره باسبا...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30207</th>\n",
              "      <td>وصف الميلودي مخاريق امين عام الاتحاد المغربي ل...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9128</th>\n",
              "      <td>عبدالاله بوسحابه اخبارنا المغربيه بعد الفضيحه ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12824</th>\n",
              "      <td>اكد حزب العداله والتنميه الاسلامي الذي يقود ال...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41515</th>\n",
              "      <td>درك الحربي اكتشف عناصر جرميه في تلقي الجنود لر...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36695</th>\n",
              "      <td>شذي يتابع ملاين العرب علي مواقع التواصل الاجتم...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48325</th>\n",
              "      <td>اعتبرت الملكه المغربيه مساء الثلاثاء ان الجوء ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25768</th>\n",
              "      <td>اقتنت الشركه الماليه الدوليه فرع البند الدولي ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52133 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3d610ed-c300-40c4-a2e7-c1e5611867ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3d610ed-c300-40c4-a2e7-c1e5611867ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3d610ed-c300-40c4-a2e7-c1e5611867ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "dataset=shuffle(dataset)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWomJ3tI_qIQ"
      },
      "source": [
        "------\n",
        "4- clean\n",
        "تنظيف البيانات"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFsW7x2E1vbw",
        "outputId": "bf71dbf6-c4fd-4113-bf0c-cbef49fd32b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "                                                    text  targe\n",
            "29519  تعهد سعد الدين العثماني رئيس الحكومه الجديد بم...      3\n",
            "42321  عبر عد من الشباب الحاملين لمشاريع بمدينه طنجه ...      2\n",
            "10209  منعت السلطات الاسبانيه مدير مكتب الجزيره باسبا...      2\n",
            "30207  وصف الميلودي مخاريق امين عام الاتحاد المغربي ل...      3\n",
            "9128   عبدالاله بوسحابه اخبارنا المغربيه بعد الفضيحه ...      2\n",
            "...                                                  ...    ...\n",
            "12824  اكد حزب العداله والتنميه الاسلامي الذي يقود ال...      3\n",
            "41515  درك الحربي اكتشف عناصر جرميه في تلقي الجنود لر...      1\n",
            "36695  شذي يتابع ملاين العرب علي مواقع التواصل الاجتم...      0\n",
            "48325  اعتبرت الملكه المغربيه مساء الثلاثاء ان الجوء ...      3\n",
            "25768  اقتنت الشركه الماليه الدوليه فرع البند الدولي ...      2\n",
            "\n",
            "[52133 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(np.sum(dataset.isnull().any(axis=1)))\n",
        "dataset= dataset.dropna()\n",
        "print(np.sum(dataset.isnull().any(axis=1)))\n",
        "\n",
        "#-------------\n",
        "def remove_hashtag(df, col = 'text'):\n",
        "    for letter in r'#.][!XR':\n",
        "      df[col] = df[col].astype(str).str.replace(letter,'', regex=True)\n",
        "           \n",
        "remove_hashtag(dataset)\n",
        "#-------------\n",
        "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
        "english_punctuations = string.punctuation\n",
        "punctuations_list = arabic_punctuations + english_punctuations\n",
        "\n",
        "def remove_punctuations(text):\n",
        "    translator = str.maketrans('', '', punctuations_list)\n",
        "    return text.translate(translator)\n",
        "#-------------\n",
        "def normalize_arabic(text):\n",
        "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    text = re.sub(\"گ\", \"ك\", text)\n",
        "    return text\n",
        "#-------------    \n",
        "def remove_repeating_char(text):\n",
        "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
        "#-------------\n",
        "def processDocument(doc, stemmer): \n",
        "\n",
        "    #Replace @username with empty string\n",
        "    doc = re.sub(r'@[^\\s]+', ' ', doc)\n",
        "    doc = re.sub(r'_', ' ', doc)\n",
        "    doc = re.sub(r'\\n', ' ', doc)\n",
        "    doc = re.sub(r'[a-z,A-Z]', '', doc)\n",
        "    doc = re.sub(r'\\d', '', doc)\n",
        "    #Convert www.* or https?://* to \" \"\n",
        "    doc = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',doc)\n",
        "    #Replace #word with word\n",
        "    doc = re.sub(r'#([^\\s]+)', r'\\1', doc)\n",
        "    # remove punctuations\n",
        "    doc= remove_punctuations(doc)\n",
        "    # normalize the tweet\n",
        "    doc= normalize_arabic(doc)\n",
        "    # remove repeated letters\n",
        "    doc=remove_repeating_char(doc)\n",
        "    #stemming\n",
        "    doc = stemmer.stem(doc)\n",
        "    \n",
        "    return doc\n",
        "    \n",
        "stemmer = ISRIStemmer()\n",
        "dataset[\"text\"] = dataset['text'].apply(lambda x: processDocument(x, stemmer))\n",
        "print(dataset)\n",
        "\n",
        "reviews = dataset['text'].values\n",
        "t = Tokenizer(oov_token='<UNK>')\n",
        "# fit the tokenizer on the documents\n",
        "t.fit_on_texts(reviews)\n",
        "t.word_index['<PAD>'] = 0\n",
        "\n",
        "VOCAB_SIZE = len(t.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Tokenizer_UNK(train_x,test_reviews,train_y, test_y):\n",
        "  norm_train_reviews = (train_x)\n",
        "  norm_test_reviews = (test_reviews)\n",
        "\n",
        "  le = LabelEncoder()\n",
        "  y_train = le.fit_transform(train_y)\n",
        "  y_test = le.transform(test_y)\n",
        "\n",
        "  from keras.utils.np_utils import to_categorical\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_test = to_categorical(y_test)\n",
        "  train_sequences = t.texts_to_sequences(norm_train_reviews)\n",
        "  test_sequences = t.texts_to_sequences(norm_test_reviews)\n",
        "  print(\"Vocabulary size={}\".format(len(t.word_index)))\n",
        "  print(\"Number of Documents={}\".format(t.document_count))\n",
        "\n",
        "  MAX_SEQUENCE_LENGTH = 1000\n",
        "  # pad dataset to a maximum review length in words\n",
        "  X_train = sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "  X_test = sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "  # X_train.shape, X_test.shape\n",
        "  return X_train, X_test ,y_train,y_test"
      ],
      "metadata": {
        "id": "lZ_oeP-UuRiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AXhAERVeXhmZ"
      },
      "outputs": [],
      "source": [
        "def set_model():\n",
        "  VOCAB_SIZE = len(t.word_index)\n",
        "  MAX_SEQUENCE_LENGTH = 1000\n",
        "  EMBED_SIZE = 300\n",
        "  \n",
        "  # create the model\n",
        "  global model\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(VOCAB_SIZE, EMBED_SIZE, input_length=MAX_SEQUENCE_LENGTH))\n",
        "  model.add(Conv1D(filters=128, kernel_size=4, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Conv1D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "\n",
        "  # model.add(Dense(1, activation='sigmoid'))\n",
        "  model.add(Dense(5, activation='sigmoid'))\n",
        "  # model.add(Flatten())\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zm-pc34lkk25"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(y_true, y_pred):\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# build train and test datasets\n",
        "reviews = dataset['text'].values\n",
        "sentiments = dataset['targe'].values\n",
        "#####\n",
        "strtfdKFold = StratifiedKFold(n_splits=4)#5\n",
        "kfold = strtfdKFold.split(reviews, sentiments)\n",
        "result_CNNClassifier=[]\n",
        "#\n",
        "for k, (train_index, test_index) in enumerate(kfold):\n",
        "    # if(os.path.exists(\"drive/MyDrive/mining/CNN.net\")):\n",
        "    #   print(\"load net\")\n",
        "    #   model = keras.models.load_model('drive/MyDrive/mining/CNN.net') \n",
        "\n",
        "    X_train_, X_test_ = reviews[train_index], reviews[test_index]\n",
        "    y_train_, y_test_ = sentiments[train_index], sentiments[test_index]\n",
        "\n",
        "    X_train, X_test ,y_train,y_test=Tokenizer_UNK(X_train_,X_test_,y_train_,y_test_)\n",
        "    # set_model()\n",
        "\n",
        "    # Fit the model\n",
        "    model=set_model()\n",
        "    EPOCHS=2  \n",
        "    BATCH_SIZE=128\n",
        "    model.fit(X_train, y_train, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
        "    y_pred=(model.predict(X_test))\n",
        "    y_classes_pre = [np.argmax(y, axis=None, out=None) for y in y_pred]\n",
        "    y_classes_test = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
        "    result_CNNClassifier.append(calculate_results(y_classes_test, y_classes_pre))\n",
        "    # model.save('drive/MyDrive/mining/CNN.net')\n",
        "    # print(\"save net\")\n",
        "\n",
        "result_CNNClassifier"
      ],
      "metadata": {
        "id": "e_0JxFY4oRce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy=0\n",
        "f1=0\n",
        "precision=0\n",
        "recall=0\n",
        "for i in result_CNNClassifier:\n",
        "  accuracy+=(i['accuracy'])\n",
        "  f1+=(i['f1'])\n",
        "  precision+=(i['precision'])\n",
        "  recall+=(i['recall'])\n",
        "\n",
        "accuracy=accuracy/len(result_CNNClassifier)\n",
        "f1=f1/len(result_CNNClassifier)\n",
        "precision=precision/len(result_CNNClassifier)\n",
        "recall=recall/len(result_CNNClassifier)\n",
        "# (result_DecisionTreeClassifier)\n",
        "results_CNNClassifier=[{'accuracy':accuracy,'f1':f1,'precision':precision,'recall':recall}]\n",
        "results_CNNClassifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDPaXpSn0p-S",
        "outputId": "ea0e6e9b-4663-417f-fc36-e668eb39c1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'accuracy': 94.78257724360446,\n",
              "  'f1': 0.9477387119920051,\n",
              "  'precision': 0.9479345864832764,\n",
              "  'recall': 0.9478257724360446}]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-5UX4r2kr7e",
        "outputId": "fff0d391-8f9b-4ef4-aba8-8e3ed1d236a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier results in dataset 1:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'accuracy': 95.19608342701729,\n",
              "  'f1': 0.9520984811390116,\n",
              "  'precision': 0.952799253715478,\n",
              "  'recall': 0.9519608342701729}]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "print('DecisionTreeClassifier results in dataset 1:')\n",
        "results_CNNClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU3FWF6a0_9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5dd415-0ade-46e8-fa03-067598583559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier results in dataset 2:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'accuracy': 95.57787784320516,\n",
              "  'f1': 0.9558535748300416,\n",
              "  'precision': 0.9565019386666695,\n",
              "  'recall': 0.9557787784320517}]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "print('DecisionTreeClassifier results in dataset 2:')\n",
        "results_CNNClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvnBdsMv1AHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45fb4fe2-b9a6-4689-fe4c-ae1bd7b403f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier results in dataset 3:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'accuracy': 94.5945934848568,\n",
              "  'f1': 0.9460234167421608,\n",
              "  'precision': 0.9465212822533673,\n",
              "  'recall': 0.9459459348485679}]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "print('DecisionTreeClassifier results in dataset 3:')\n",
        "results_CNNClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4AvEaX51ASP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee6b6ea-8cdf-4dda-bde4-f2ee52b08b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier results in dataset 4:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'accuracy': 94.78257724360446,\n",
              "  'f1': 0.9477387119920051,\n",
              "  'precision': 0.9479345864832764,\n",
              "  'recall': 0.9478257724360446}]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "print('DecisionTreeClassifier results in dataset 4:')\n",
        "results_CNNClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Result=[\n",
        "  {'accuracy': 95.19608342701729,\n",
        "  'f1': 0.9520984811390116,\n",
        "  'precision': 0.952799253715478,\n",
        "  'recall': 0.9519608342701729}\n",
        "  ,\n",
        "  {'accuracy': 95.57787784320516,\n",
        "  'f1': 0.9558535748300416,\n",
        "  'precision': 0.9565019386666695,\n",
        "  'recall': 0.9557787784320517}\n",
        "  ,\n",
        "  {'accuracy': 94.5945934848568,\n",
        "  'f1': 0.9460234167421608,\n",
        "  'precision': 0.9465212822533673,\n",
        "  'recall': 0.9459459348485679}\n",
        "  ,\n",
        " {'accuracy': 94.78257724360446,\n",
        "  'f1': 0.9477387119920051,\n",
        "  'precision': 0.9479345864832764,\n",
        "  'recall': 0.9478257724360446}\n",
        "  ]\n",
        "\n",
        "accuracy=0\n",
        "f1=0\n",
        "precision=0\n",
        "recall=0\n",
        "for i in Final_Result:\n",
        "  accuracy+=(i['accuracy'])\n",
        "  f1+=(i['f1'])\n",
        "  precision+=(i['precision'])\n",
        "  recall+=(i['recall'])\n",
        "\n",
        "accuracy=accuracy/len(Final_Result)\n",
        "f1=f1/len(Final_Result)\n",
        "precision=precision/len(Final_Result)\n",
        "recall=recall/len(Final_Result)\n",
        "# (result_DecisionTreeClassifier)\n",
        "Final_Result=[{'accuracy':accuracy,'f1':f1,'precision':precision,'recall':recall}]\n",
        "\n",
        "print('Final_Result:')\n",
        "print(Final_Result)"
      ],
      "metadata": {
        "id": "-lB0leWu1IwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f16600-3be5-4763-f9f5-c7922c142b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final_Result:\n",
            "[{'accuracy': 95.03778299967092, 'f1': 0.9504285461758049, 'precision': 0.9509392652796977, 'recall': 0.9503778299967094}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_qyQzgTNUlO"
      },
      "source": [
        "---------------\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CNN_<UNK>.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}