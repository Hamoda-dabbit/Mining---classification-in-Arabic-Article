{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamoda-dabbit/Mining---classification-in-Arabic-Article/blob/main/CNN/CNN_%3CUNK%3E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKSuILzq_b-8"
      },
      "source": [
        " 1-import library\n",
        " \n",
        "  إستيراد المكتبات"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.utils import shuffle\n",
        "import nltk \n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "# from nltk.tokenize import word_tokenize\n",
        "# from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "import re\n",
        "import string\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.pipeline import Pipeline\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.calibration import CalibratedClassifierCV\n",
        "# from sklearn.feature_selection import SelectKBest\n",
        "# from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "# from joblib import dump, load\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "# fix random seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYp37W3G3c-N",
        "outputId": "1dd86613-fa68-490b-ecef-97b36889bff1"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY_2pUn__oh8"
      },
      "source": [
        "--------\n",
        "\n",
        "2- import Datasets\n",
        "\n",
        "استيراد ملفات البيانات\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITaTjKYUJGKx",
        "outputId": "037fe9cb-cb23-4a91-ec07-216ce2f4a211"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 52133 entries, 40170 to 15795\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    52133 non-null  object\n",
            " 1   targe   52133 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.2+ MB\n"
          ]
        }
      ],
      "source": [
        "# dataset = pd.read_excel(\"drive/MyDrive/mining/1.xlsx\")\n",
        "# dataset = pd.read_excel(\"drive/MyDrive/mining/2.xlsx\")\n",
        "# dataset = pd.read_excel(\"drive/MyDrive/mining/3.xlsx\")\n",
        "ddatasetf = pd.read_excel(\"drive/MyDrive/mining/4.xlsx\")\n",
        "\n",
        "dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjXeZSy9_fB2"
      },
      "source": [
        "------\n",
        "3- shuffle  \n",
        "بعثرة البيانات"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "n70SDzKWdM5_",
        "outputId": "d9d8fe78-72b9-48a3-dcdb-2f051ce15b39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    text  targe\n",
              "29519  تعهد سعد الدين العثماني رئيس الحكومه الجديد بم...      3\n",
              "42321  عبر عد من الشباب الحاملين لمشاريع بمدينه طنجه ...      2\n",
              "10209  منعت السلطات الاسبانيه مدير مكتب الجزيره باسبا...      2\n",
              "30207  وصف الميلودي مخاريق امين عام الاتحاد المغربي ل...      3\n",
              "9128   عبدالاله بوسحابه اخبارنا المغربيه بعد الفضيحه ...      2\n",
              "...                                                  ...    ...\n",
              "12824  اكد حزب العداله والتنميه الاسلامي الذي يقود ال...      3\n",
              "41515  درك الحربي اكتشف عناصر جرميه في تلقي الجنود لر...      1\n",
              "36695  شذي يتابع ملاين العرب علي مواقع التواصل الاجتم...      0\n",
              "48325  اعتبرت الملكه المغربيه مساء الثلاثاء ان الجوء ...      3\n",
              "25768  اقتنت الشركه الماليه الدوليه فرع البند الدولي ...      2\n",
              "\n",
              "[52133 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e3d610ed-c300-40c4-a2e7-c1e5611867ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>targe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29519</th>\n",
              "      <td>تعهد سعد الدين العثماني رئيس الحكومه الجديد بم...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42321</th>\n",
              "      <td>عبر عد من الشباب الحاملين لمشاريع بمدينه طنجه ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10209</th>\n",
              "      <td>منعت السلطات الاسبانيه مدير مكتب الجزيره باسبا...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30207</th>\n",
              "      <td>وصف الميلودي مخاريق امين عام الاتحاد المغربي ل...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9128</th>\n",
              "      <td>عبدالاله بوسحابه اخبارنا المغربيه بعد الفضيحه ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12824</th>\n",
              "      <td>اكد حزب العداله والتنميه الاسلامي الذي يقود ال...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41515</th>\n",
              "      <td>درك الحربي اكتشف عناصر جرميه في تلقي الجنود لر...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36695</th>\n",
              "      <td>شذي يتابع ملاين العرب علي مواقع التواصل الاجتم...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48325</th>\n",
              "      <td>اعتبرت الملكه المغربيه مساء الثلاثاء ان الجوء ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25768</th>\n",
              "      <td>اقتنت الشركه الماليه الدوليه فرع البند الدولي ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>52133 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e3d610ed-c300-40c4-a2e7-c1e5611867ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e3d610ed-c300-40c4-a2e7-c1e5611867ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e3d610ed-c300-40c4-a2e7-c1e5611867ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "dataset=shuffle(dataset)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWomJ3tI_qIQ"
      },
      "source": [
        "------\n",
        "4- clean\n",
        "تنظيف البيانات"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFsW7x2E1vbw",
        "outputId": "bf71dbf6-c4fd-4113-bf0c-cbef49fd32b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "                                                    text  targe\n",
            "29519  تعهد سعد الدين العثماني رئيس الحكومه الجديد بم...      3\n",
            "42321  عبر عد من الشباب الحاملين لمشاريع بمدينه طنجه ...      2\n",
            "10209  منعت السلطات الاسبانيه مدير مكتب الجزيره باسبا...      2\n",
            "30207  وصف الميلودي مخاريق امين عام الاتحاد المغربي ل...      3\n",
            "9128   عبدالاله بوسحابه اخبارنا المغربيه بعد الفضيحه ...      2\n",
            "...                                                  ...    ...\n",
            "12824  اكد حزب العداله والتنميه الاسلامي الذي يقود ال...      3\n",
            "41515  درك الحربي اكتشف عناصر جرميه في تلقي الجنود لر...      1\n",
            "36695  شذي يتابع ملاين العرب علي مواقع التواصل الاجتم...      0\n",
            "48325  اعتبرت الملكه المغربيه مساء الثلاثاء ان الجوء ...      3\n",
            "25768  اقتنت الشركه الماليه الدوليه فرع البند الدولي ...      2\n",
            "\n",
            "[52133 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "print(np.sum(dataset.isnull().any(axis=1)))\n",
        "dataset= dataset.dropna()\n",
        "print(np.sum(dataset.isnull().any(axis=1)))\n",
        "\n",
        "#-------------\n",
        "def remove_hashtag(df, col = 'text'):\n",
        "    for letter in r'#.][!XR':\n",
        "      df[col] = df[col].astype(str).str.replace(letter,'', regex=True)\n",
        "           \n",
        "remove_hashtag(dataset)\n",
        "#-------------\n",
        "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
        "english_punctuations = string.punctuation\n",
        "punctuations_list = arabic_punctuations + english_punctuations\n",
        "\n",
        "def remove_punctuations(text):\n",
        "    translator = str.maketrans('', '', punctuations_list)\n",
        "    return text.translate(translator)\n",
        "#-------------\n",
        "def normalize_arabic(text):\n",
        "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    text = re.sub(\"گ\", \"ك\", text)\n",
        "    return text\n",
        "#-------------    \n",
        "def remove_repeating_char(text):\n",
        "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
        "#-------------\n",
        "def processDocument(doc, stemmer): \n",
        "\n",
        "    #Replace @username with empty string\n",
        "    doc = re.sub(r'@[^\\s]+', ' ', doc)\n",
        "    doc = re.sub(r'_', ' ', doc)\n",
        "    doc = re.sub(r'\\n', ' ', doc)\n",
        "    doc = re.sub(r'[a-z,A-Z]', '', doc)\n",
        "    doc = re.sub(r'\\d', '', doc)\n",
        "    #Convert www.* or https?://* to \" \"\n",
        "    doc = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',doc)\n",
        "    #Replace #word with word\n",
        "    doc = re.sub(r'#([^\\s]+)', r'\\1', doc)\n",
        "    # remove punctuations\n",
        "    doc= remove_punctuations(doc)\n",
        "    # normalize the tweet\n",
        "    doc= normalize_arabic(doc)\n",
        "    # remove repeated letters\n",
        "    doc=remove_repeating_char(doc)\n",
        "    #stemming\n",
        "    doc = stemmer.stem(doc)\n",
        "    \n",
        "    return doc\n",
        "    \n",
        "stemmer = ISRIStemmer()\n",
        "dataset[\"text\"] = dataset['text'].apply(lambda x: processDocument(x, stemmer))\n",
        "print(dataset)\n",
        "\n",
        "reviews = dataset['text'].values\n",
        "t = Tokenizer(oov_token='<UNK>')\n",
        "# fit the tokenizer on the documents\n",
        "t.fit_on_texts(reviews)\n",
        "t.word_index['<PAD>'] = 0\n",
        "\n",
        "VOCAB_SIZE = len(t.word_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Tokenizer_UNK(train_x,test_reviews,train_y, test_y):\n",
        "  norm_train_reviews = (train_x)\n",
        "  norm_test_reviews = (test_reviews)\n",
        "\n",
        "  le = LabelEncoder()\n",
        "  y_train = le.fit_transform(train_y)\n",
        "  y_test = le.transform(test_y)\n",
        "\n",
        "  from keras.utils.np_utils import to_categorical\n",
        "  y_train = to_categorical(y_train)\n",
        "  y_test = to_categorical(y_test)\n",
        "  # print(y[0])\n",
        "  # global t\n",
        "  # t = Tokenizer(oov_token='<UNK>')\n",
        "  # # fit the tokenizer on the documents\n",
        "  # t.fit_on_texts(norm_train_reviews)\n",
        "  # t.word_index['<PAD>'] = 0\n",
        "  # max([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), min([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), t.word_index['<UNK>']\n",
        "  train_sequences = t.texts_to_sequences(norm_train_reviews)\n",
        "  test_sequences = t.texts_to_sequences(norm_test_reviews)\n",
        "  print(\"Vocabulary size={}\".format(len(t.word_index)))\n",
        "  print(\"Number of Documents={}\".format(t.document_count))\n",
        "\n",
        "  MAX_SEQUENCE_LENGTH = 1000\n",
        "  # pad dataset to a maximum review length in words\n",
        "  X_train = sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "  X_test = sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "  # X_train.shape, X_test.shape\n",
        "  return X_train, X_test ,y_train,y_test"
      ],
      "metadata": {
        "id": "lZ_oeP-UuRiQ"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "AXhAERVeXhmZ"
      },
      "outputs": [],
      "source": [
        "def set_model():\n",
        "  VOCAB_SIZE = len(t.word_index)\n",
        "  MAX_SEQUENCE_LENGTH = 1000\n",
        "  EMBED_SIZE = 300\n",
        "  \n",
        "  # create the model\n",
        "  global model\n",
        "  model = Sequential()\n",
        "  model.add(Embedding(VOCAB_SIZE, EMBED_SIZE, input_length=MAX_SEQUENCE_LENGTH))\n",
        "  model.add(Conv1D(filters=128, kernel_size=4, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Conv1D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
        "  model.add(MaxPooling1D(pool_size=2))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "\n",
        "  # model.add(Dense(1, activation='sigmoid'))\n",
        "  model.add(Dense(5, activation='sigmoid'))\n",
        "  # model.add(Flatten())\n",
        "  model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "zm-pc34lkk25"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(y_true, y_pred):\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import os.path\n",
        "from tensorflow import keras\n",
        "\n",
        "# build train and test datasets\n",
        "reviews = dataset['text'].values\n",
        "sentiments = dataset['targe'].values\n",
        "#####\n",
        "strtfdKFold = StratifiedKFold(n_splits=4)#5\n",
        "kfold = strtfdKFold.split(reviews, sentiments)\n",
        "result_CNNClassifier=[]\n",
        "#\n",
        "for k, (train_index, test_index) in enumerate(kfold):\n",
        "    # if(os.path.exists(\"drive/MyDrive/mining/CNN.net\")):\n",
        "    #   print(\"load net\")\n",
        "    #   model = keras.models.load_model('drive/MyDrive/mining/CNN.net') \n",
        "\n",
        "    X_train_, X_test_ = reviews[train_index], reviews[test_index]\n",
        "    y_train_, y_test_ = sentiments[train_index], sentiments[test_index]\n",
        "\n",
        "    X_train, X_test ,y_train,y_test=Tokenizer_UNK(X_train_,X_test_,y_train_,y_test_)\n",
        "    # set_model()\n",
        "\n",
        "    # Fit the model\n",
        "    model=set_model()\n",
        "    EPOCHS=2  \n",
        "    BATCH_SIZE=128\n",
        "    model.fit(X_train, y_train, validation_split=0.1, epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)\n",
        "    y_pred=(model.predict(X_test))\n",
        "    y_classes_pre = [np.argmax(y, axis=None, out=None) for y in y_pred]\n",
        "    y_classes_test = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
        "    result_CNNClassifier.append(calculate_results(y_classes_test, y_classes_pre))\n",
        "    # model.save('drive/MyDrive/mining/CNN.net')\n",
        "    # print(\"save net\")\n",
        "\n",
        "result_CNNClassifier"
      ],
      "metadata": {
        "id": "e_0JxFY4oRce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy=0\n",
        "f1=0\n",
        "precision=0\n",
        "recall=0\n",
        "for i in result_CNNClassifier:\n",
        "  accuracy+=(i['accuracy'])\n",
        "  f1+=(i['f1'])\n",
        "  precision+=(i['precision'])\n",
        "  recall+=(i['recall'])\n",
        "\n",
        "accuracy=accuracy/len(result_CNNClassifier)\n",
        "f1=f1/len(result_CNNClassifier)\n",
        "precision=precision/len(result_CNNClassifier)\n",
        "recall=recall/len(result_CNNClassifier)\n",
        "# (result_DecisionTreeClassifier)\n",
        "results_CNNClassifier=[{'accuracy':accuracy,'f1':f1,'precision':precision,'recall':recall}]\n",
        "results_CNNClassifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDPaXpSn0p-S",
        "outputId": "ea0e6e9b-4663-417f-fc36-e668eb39c1b9"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'accuracy': 94.78257724360446,\n",
              "  'f1': 0.9477387119920051,\n",
              "  'precision': 0.9479345864832764,\n",
              "  'recall': 0.9478257724360446}]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "e-5UX4r2kr7e",
        "outputId": "fff0d391-8f9b-4ef4-aba8-8e3ed1d236a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier results in dataset 1:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'accuracy': 95.19608342701729,\n",
              "  'f1': 0.9520984811390116,\n",
              "  'precision': 0.952799253715478,\n",
              "  'recall': 0.9519608342701729}]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "print('DecisionTreeClassifier results in dataset 1:')\n",
        "results_CNNClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "yU3FWF6a0_9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5dd415-0ade-46e8-fa03-067598583559"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier results in dataset 2:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'accuracy': 95.57787784320516,\n",
              "  'f1': 0.9558535748300416,\n",
              "  'precision': 0.9565019386666695,\n",
              "  'recall': 0.9557787784320517}]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "print('DecisionTreeClassifier results in dataset 2:')\n",
        "results_CNNClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "OvnBdsMv1AHc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45fb4fe2-b9a6-4689-fe4c-ae1bd7b403f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier results in dataset 3:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'accuracy': 94.5945934848568,\n",
              "  'f1': 0.9460234167421608,\n",
              "  'precision': 0.9465212822533673,\n",
              "  'recall': 0.9459459348485679}]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "print('DecisionTreeClassifier results in dataset 3:')\n",
        "results_CNNClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "P4AvEaX51ASP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee6b6ea-8cdf-4dda-bde4-f2ee52b08b3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecisionTreeClassifier results in dataset 4:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'accuracy': 94.78257724360446,\n",
              "  'f1': 0.9477387119920051,\n",
              "  'precision': 0.9479345864832764,\n",
              "  'recall': 0.9478257724360446}]"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "print('DecisionTreeClassifier results in dataset 4:')\n",
        "results_CNNClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Final_Result=[\n",
        "  {'accuracy': 95.19608342701729,\n",
        "  'f1': 0.9520984811390116,\n",
        "  'precision': 0.952799253715478,\n",
        "  'recall': 0.9519608342701729}\n",
        "  ,\n",
        "  {'accuracy': 95.57787784320516,\n",
        "  'f1': 0.9558535748300416,\n",
        "  'precision': 0.9565019386666695,\n",
        "  'recall': 0.9557787784320517}\n",
        "  ,\n",
        "  {'accuracy': 94.5945934848568,\n",
        "  'f1': 0.9460234167421608,\n",
        "  'precision': 0.9465212822533673,\n",
        "  'recall': 0.9459459348485679}\n",
        "  ,\n",
        " {'accuracy': 94.78257724360446,\n",
        "  'f1': 0.9477387119920051,\n",
        "  'precision': 0.9479345864832764,\n",
        "  'recall': 0.9478257724360446}\n",
        "  ]\n",
        "\n",
        "accuracy=0\n",
        "f1=0\n",
        "precision=0\n",
        "recall=0\n",
        "for i in Final_Result:\n",
        "  accuracy+=(i['accuracy'])\n",
        "  f1+=(i['f1'])\n",
        "  precision+=(i['precision'])\n",
        "  recall+=(i['recall'])\n",
        "\n",
        "accuracy=accuracy/len(Final_Result)\n",
        "f1=f1/len(Final_Result)\n",
        "precision=precision/len(Final_Result)\n",
        "recall=recall/len(Final_Result)\n",
        "# (result_DecisionTreeClassifier)\n",
        "Final_Result=[{'accuracy':accuracy,'f1':f1,'precision':precision,'recall':recall}]\n",
        "\n",
        "print('Final_Result:')\n",
        "print(Final_Result)"
      ],
      "metadata": {
        "id": "-lB0leWu1IwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4f16600-3be5-4763-f9f5-c7922c142b38"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final_Result:\n",
            "[{'accuracy': 95.03778299967092, 'f1': 0.9504285461758049, 'precision': 0.9509392652796977, 'recall': 0.9503778299967094}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_qyQzgTNUlO"
      },
      "source": [
        "---------------\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CNN_<UNK>.ipynb",
      "provenance": [],
      "mount_file_id": "https://github.com/Hamoda-dabbit/Mining---classification-in-Arabic-Article/blob/main/CNN/CNN_%3CUNK%3E.ipynb",
      "authorship_tag": "ABX9TyMdJPgvmEfyLjfKxxku3MUH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}