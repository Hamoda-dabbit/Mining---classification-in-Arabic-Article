{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamoda-dabbit/Mining---classification-in-Arabic-Article/blob/main/CNN_%3CUNK%3E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKSuILzq_b-8"
      },
      "source": [
        " 1- إستيراد المكتبات"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ZHYHdQtygBh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv1D\n",
        "from tensorflow.keras.layers import MaxPooling1D\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import nltk\n",
        "# fix random seed for reproducibility\n",
        "seed = 42\n",
        "np.random.seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IY_2pUn__oh8"
      },
      "source": [
        "--------\n",
        "\n",
        "2- استيراد ملفات البيانات"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ITaTjKYUJGKx",
        "outputId": "93cd0873-5203-4fa9-c02d-93b33695e616"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 17500 entries, 0 to 17499\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    17361 non-null  object\n",
            " 1   targe   17500 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 273.6+ KB\n"
          ]
        }
      ],
      "source": [
        "dataset = pd.read_excel(\"drive/MyDrive/mining/1.xlsx\")\n",
        "dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjXeZSy9_fB2"
      },
      "source": [
        "------\n",
        "3- shuffle  \n",
        "بعثرة البيانات"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "n70SDzKWdM5_",
        "outputId": "dfc2faf4-f3f5-43a6-d819-491e2df377de"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-ea51ae3b-aeac-4b52-aefa-707af2237081\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>targe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1411</th>\n",
              "      <td>علمت الصباح أن الفيلم الجديد للمخرج نبيل عيوش ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7555</th>\n",
              "      <td>يستعد المغرب لإطلاق أول دفعة من السندات الإسلا...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4930</th>\n",
              "      <td>استقلال القاضي هدف ثابت وحتمي لتحقيق العدالة ف...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10054</th>\n",
              "      <td>بلغ حجم الإعفاءات الضريبية خلال العام الحالي م...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2714</th>\n",
              "      <td>أخبارنا المغربية سناء الوردي استغلت الفنانة ال...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ea51ae3b-aeac-4b52-aefa-707af2237081')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ea51ae3b-aeac-4b52-aefa-707af2237081 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ea51ae3b-aeac-4b52-aefa-707af2237081');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                    text  targe\n",
              "1411   علمت الصباح أن الفيلم الجديد للمخرج نبيل عيوش ...      0\n",
              "7555   يستعد المغرب لإطلاق أول دفعة من السندات الإسلا...      2\n",
              "4930   استقلال القاضي هدف ثابت وحتمي لتحقيق العدالة ف...      1\n",
              "10054  بلغ حجم الإعفاءات الضريبية خلال العام الحالي م...      2\n",
              "2714   أخبارنا المغربية سناء الوردي استغلت الفنانة ال...      0"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "dataset=shuffle(dataset)\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWomJ3tI_qIQ"
      },
      "source": [
        "------\n",
        "4- clean\n",
        "تنظيف البيانات"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFsW7x2E1vbw",
        "outputId": "b149a032-d61d-4970-9caf-fe40467167f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "139\n",
            "0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import re\n",
        "from nltk.stem.isri import ISRIStemmer\n",
        "\n",
        "print(np.sum(dataset.isnull().any(axis=1)))\n",
        "dataset= dataset.dropna()\n",
        "print(np.sum(dataset.isnull().any(axis=1)))\n",
        "\n",
        "#-------------\n",
        "def remove_hashtag(df, col = 'text'):\n",
        "    for letter in r'#.][!XR':\n",
        "      df[col] = df[col].astype(str).str.replace(letter,'', regex=True)\n",
        "           \n",
        "remove_hashtag(dataset)\n",
        "#-------------\n",
        "arabic_punctuations = '''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
        "english_punctuations = string.punctuation\n",
        "punctuations_list = arabic_punctuations + english_punctuations\n",
        "\n",
        "def remove_punctuations(text):\n",
        "    translator = str.maketrans('', '', punctuations_list)\n",
        "    return text.translate(translator)\n",
        "#-------------\n",
        "def normalize_arabic(text):\n",
        "    text = re.sub(\"[إأآا]\", \"ا\", text)\n",
        "    text = re.sub(\"ى\", \"ي\", text)\n",
        "    text = re.sub(\"ة\", \"ه\", text)\n",
        "    text = re.sub(\"گ\", \"ك\", text)\n",
        "    return text\n",
        "#-------------    \n",
        "def remove_repeating_char(text):\n",
        "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
        "#-------------\n",
        "def processDocument(doc, stemmer): \n",
        "\n",
        "    #Replace @username with empty string\n",
        "    doc = re.sub(r'@[^\\s]+', ' ', doc)\n",
        "    doc = re.sub(r'_', ' ', doc)\n",
        "    doc = re.sub(r'\\n', ' ', doc)\n",
        "    doc = re.sub(r'[a-z,A-Z]', '', doc)\n",
        "    doc = re.sub(r'\\d', '', doc)\n",
        "    #Convert www.* or https?://* to \" \"\n",
        "    doc = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))',' ',doc)\n",
        "    #Replace #word with word\n",
        "    doc = re.sub(r'#([^\\s]+)', r'\\1', doc)\n",
        "    # remove punctuations\n",
        "    doc= remove_punctuations(doc)\n",
        "    # normalize the tweet\n",
        "    doc= normalize_arabic(doc)\n",
        "    # remove repeated letters\n",
        "    doc=remove_repeating_char(doc)\n",
        "    #stemming\n",
        "    doc = stemmer.stem(doc)\n",
        "    \n",
        "    return doc\n",
        "    \n",
        "stemmer = ISRIStemmer()\n",
        "dataset[\"text\"] = dataset['text'].apply(lambda x: processDocument(x, stemmer))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpwueLn6V-qF"
      },
      "outputs": [],
      "source": [
        "# build train and test datasets\n",
        "reviews = dataset['text'].values\n",
        "sentiments = dataset['targe'].values\n",
        "# print(y[0])\n",
        "\n",
        "\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# x_train, x_test, y_train, y_test = train_test_split(x.values, y_cat, test_size=0.2)\n",
        "# train_reviews = reviews[:35000]\n",
        "train_reviews = reviews[:14000]\n",
        "train_sentiments = sentiments[:14000]\n",
        "# y_cat = y[:14000]\n",
        "\n",
        "# test_reviews = reviews[35000:]\n",
        "test_reviews = reviews[14000:]\n",
        "test_sentiments = sentiments[14000:]\n",
        "# y_test = y[14000:]\n",
        "\n",
        "norm_train_reviews = (train_reviews)\n",
        "norm_test_reviews = (test_reviews)\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(train_sentiments)\n",
        "y_test = le.transform(test_sentiments)\n",
        "\n",
        "\n",
        "\n",
        "# print(y_train)\n",
        "# y_test = to_categorical(y_test)\n",
        "# y_cat\n",
        "\n",
        "\n",
        "#convert text to numper \n",
        "\n",
        "num_classes=5 #  -> 0,  -> 1 , 2, 3, ,4\n",
        "\n",
        "# print(y[0])\n",
        "#convert numper to array  1=>[0,1,0,0,0]\n",
        "#Converting prediction to categorical\n",
        "from keras.utils.np_utils import to_categorical\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "# print(y[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COgKPRmLpxTu"
      },
      "source": [
        "## Preprocessing\n",
        "\n",
        "To prepare text data for our deep learning model, we transform each review into a sequence.\n",
        "Every word in the review is mapped to an integer index and thus the sentence turns into a sequence of numbers.\n",
        "\n",
        "To perform this transformation, keras provides the ```Tokenizer```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dff8sG63cw03",
        "outputId": "5fdca51d-e66a-46ca-9c4d-9c7f338f0dfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size=160097\n",
            "Number of Documents=14000\n"
          ]
        }
      ],
      "source": [
        "t = Tokenizer(oov_token='<UNK>')\n",
        "# fit the tokenizer on the documents\n",
        "t.fit_on_texts(norm_train_reviews)\n",
        "t.word_index['<PAD>'] = 0\n",
        "# max([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), min([(k, v) for k, v in t.word_index.items()], key = lambda x:x[1]), t.word_index['<UNK>']\n",
        "train_sequences = t.texts_to_sequences(norm_train_reviews)\n",
        "test_sequences = t.texts_to_sequences(norm_test_reviews)\n",
        "print(\"Vocabulary size={}\".format(len(t.word_index)))\n",
        "print(\"Number of Documents={}\".format(t.document_count))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfZwP6C8pxT8"
      },
      "source": [
        "### Sequence Normalization\n",
        "\n",
        "Not all reviews are of same length. To handle this difference in length of reviews, we define a maximum length.\n",
        "For reviews which are smaller than this length, we pad them with zeros which longer ones are truncated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAnv99kzWA5k",
        "outputId": "b6e7d4c2-1737-4f5c-b248-e8e07948560b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((14000, 1000), (3361, 1000))"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "# pad dataset to a maximum review length in words\n",
        "X_train = sequence.pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "X_test = sequence.pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9X_4ticSpxUC"
      },
      "source": [
        "### Encoding Labels\n",
        "\n",
        "The dataset contains labels of the form positive/negative. The following step encodes the labels using ```sklearn's``` ```LabelEncoder```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCjRYBh2pxUM"
      },
      "source": [
        "## Prepare the Model\n",
        "\n",
        "Since textual data is a sequence of words, we utilize ```1D``` convolutions to scan through the sentences.\n",
        "The model first transforms each word into lower dimensional embedding/vector space followed by 1d convolutions and then passing the data through dense layers before the final layer for classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXhAERVeXhmZ",
        "outputId": "91007ffa-9f44-4f16-f2aa-8e9e4217c5df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 1000, 300)         48029100  \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 1000, 128)         153728    \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPooling  (None, 500, 128)         0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 500, 64)           32832     \n",
            "                                                                 \n",
            " max_pooling1d_4 (MaxPooling  (None, 250, 64)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 250, 32)           8224      \n",
            "                                                                 \n",
            " max_pooling1d_5 (MaxPooling  (None, 125, 32)          0         \n",
            " 1D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4000)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               1024256   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 1285      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49,249,425\n",
            "Trainable params: 49,249,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "VOCAB_SIZE = len(t.word_index)\n",
        "EMBED_SIZE = 300\n",
        "EPOCHS=2\n",
        "BATCH_SIZE=128\n",
        "# create the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(VOCAB_SIZE, EMBED_SIZE, input_length=MAX_SEQUENCE_LENGTH))\n",
        "model.add(Conv1D(filters=128, kernel_size=4, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=64, kernel_size=4, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Conv1D(filters=32, kernel_size=4, padding='same', activation='relu'))\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "# model.add(Dense(1, activation='sigmoid'))\n",
        "model.add(Dense(5, activation='sigmoid'))\n",
        "# model.add(Flatten())\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szNl8QiQpxUa"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uc0jXszf5ob",
        "outputId": "c7ae97a6-c404-4274-b5ba-4d48151548d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "99/99 [==============================] - 367s 4s/step - loss: 0.3095 - accuracy: 0.5965 - val_loss: 0.0755 - val_accuracy: 0.9357\n",
            "Epoch 2/2\n",
            "99/99 [==============================] - 360s 4s/step - loss: 0.0383 - accuracy: 0.9717 - val_loss: 0.0585 - val_accuracy: 0.9571\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f14232bb210>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit the model\n",
        "model.fit(X_train, y_train, \n",
        "          validation_split=0.1,\n",
        "          epochs=EPOCHS, \n",
        "          batch_size=BATCH_SIZE, \n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuKczZqYpxUk"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zik9CWQgNlK",
        "outputId": "867dbe32-d6c2-43f0-c521-5d20b253bba3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "106/106 [==============================] - 22s 210ms/step - loss: 0.0769 - accuracy: 0.9458\n",
            "Accuracy: 94.58%\n"
          ]
        }
      ],
      "source": [
        "# Final evaluation of the model\n",
        "scores = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "zm-pc34lkk25"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "def calculate_results(y_true, y_pred):\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                  \"precision\": model_precision,\n",
        "                  \"recall\": model_recall,\n",
        "                  \"f1\": model_f1}\n",
        "  return model_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "e-5UX4r2kr7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b28ea46-73ca-43cb-dbe7-c177c01f04d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 94.58494495685808,\n",
              " 'f1': 0.9460435614590436,\n",
              " 'precision': 0.9479702608343531,\n",
              " 'recall': 0.9458494495685807}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "y_pred=(model.predict(X_test))\n",
        "y_classes_pre = [np.argmax(y, axis=None, out=None) for y in y_pred]\n",
        "y_classes_test = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
        "\n",
        "result_CNN=(calculate_results(y_classes_test, y_classes_pre))\n",
        "result_CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_qyQzgTNUlO"
      },
      "source": [
        "---------------\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B904TLKNiA1B"
      },
      "outputs": [],
      "source": [
        "# predictions = model.predict_classes(X_test).ravel()\n",
        "# predictions[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVjbqjaopxU-"
      },
      "outputs": [],
      "source": [
        "# predictions = ['positive' if item == 1 else 'negative' for item in predictions]\n",
        "# predictions[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mINpo7mDpxVC"
      },
      "outputs": [],
      "source": [
        "# from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# labels = ['negative', 'positive']\n",
        "# print(classification_report(test_sentiments, predictions))\n",
        "# pd.DataFrame(confusion_matrix(test_sentiments, predictions), index=labels, columns=labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CNN_<UNK>.ipynb",
      "provenance": [],
      "mount_file_id": "1i7g6Ke3zrK5CX7ryTc0ZnnXzX5_Velpy",
      "authorship_tag": "ABX9TyPw0pY8xIwEH+zugfvZYpSU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}